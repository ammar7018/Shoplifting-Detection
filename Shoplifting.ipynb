{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHShwyoQUuk_"
      },
      
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yutoXR5QovnF"
      },
      "source": [
        "Import used library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6RTI55YTtARN"
      },
      "outputs": [],
      "source": [
        "# Import the required libraries.\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import shutil\n",
        "\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from moviepy import *\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1Bb4yFtGtAzB"
      },
      "outputs": [],
      "source": [
        "seed_constant = 2\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Qpgo0ho-LD"
      },
      "source": [
        "Read Drive to access data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUf0rrWbtipH",
        "outputId": "7a73bb5a-8da8-4118-81ed-c31b80422c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub7fLsQXpX8g"
      },
      "source": [
        "Get the names of all classes/categories in shoplifting dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCJpSL5PuYD6",
        "outputId": "341e4801-6b73-4378-c1f6-83f8258023f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not Shop Lifters', 'shop lifter']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "all_classes_names = os.listdir('/content/drive/MyDrive/Phase 1 Dataset')\n",
        "all_classes_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "rKAf4Oxcvo4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO_fM0dIpnJN"
      },
      "source": [
        "Print the count of each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0t2qkRAuu2k",
        "outputId": "62308b32-3989-4161-dfcc-327d39e22c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal 565\n",
            "shoplifting 0\n"
          ]
        }
      ],
      "source": [
        "print('normal', len(os.listdir('/content/drive/MyDrive/Phase 1 Dataset/not Shop Lifters')))\n",
        "print('shoplifting', len(os.listdir('/content/drive/MyDrive/Phase 1 Dataset/shop lifter')))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "source_folder = '/content/drive/MyDrive/Phase 1 Dataset/not Shop Lifters'\n",
        "destination_folder = '/tmp/not_Shop_Lifters_Copyyy'\n",
        "move_to_folder = '/tmp/first_128_files'\n",
        "\n",
        "# Create a copy of the \"not Shop Lifters\" folder in the \"/tmp\" directory\n",
        "shutil.copytree(source_folder, destination_folder)\n",
        "os.makedirs(move_to_folder, exist_ok=True)\n",
        "# Move the first 128 files from the copied folder to another folder\n",
        "files_to_move = os.listdir(destination_folder)[:128]\n",
        "for file_name in files_to_move:\n",
        "    file_path = os.path.join(destination_folder, file_name)\n",
        "    destination_path = os.path.join(move_to_folder, file_name)\n",
        "    shutil.move(file_path, destination_path)\n",
        "\n",
        "# After moving the files, you can print the number of files in each folder to verify\n",
        "print(\"Number of files in the copied folder:\", len(os.listdir(destination_folder)))\n",
        "print(\"Number of files in the moved folder:\", len(os.listdir(move_to_folder)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWy-joV3uMLi",
        "outputId": "7829c30e-3407-4cea-e6c0-9cdb8aa8d943"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in the copied folder: 437\n",
            "Number of files in the moved folder: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsJaclwaBTIT"
      },
      "source": [
        "Augment the shop Lifting data to avoid Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQLMt7fg6B1o",
        "outputId": "5d1e78b0-a1f2-4237-8f5b-1c8a4cd9733e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video 'shop_lifter_3.mp4' augmented successfully.\n",
            "Video 'shop_lifter_57.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_71.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_94_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_42.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_129_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_154.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_40_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_114.mp4' augmented successfully.\n",
            "Video 'shop_lifter_41.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_158_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_29.mp4' augmented successfully.\n",
            "Video 'shop_lifter_51.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_48.mp4' augmented successfully.\n",
            "Video 'shop_lifter_23.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_121.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_103.mp4' augmented successfully.\n",
            "Video 'shop_lifter_66.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_105_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_215_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_112.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_34.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_124.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_28.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_3.mp4' augmented successfully.\n",
            "Video 'shop_lifter_42.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_51_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_27.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_179_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_26.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_192_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_173_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_106_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_72_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_108_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_110.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_136_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_194_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_121_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_191_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_65.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_142_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_38.mp4' augmented successfully.\n",
            "Video 'shop_lifter_18.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_110.mp4' augmented successfully.\n",
            "Video 'shop_lifter_16.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_183_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_100.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_71_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_190.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_17.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_89.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_178.mp4' augmented successfully.\n",
            "Video 'shop_lifter_10.mp4' augmented successfully.\n",
            "Video 'shop_lifter_25.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_15_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_125.mp4' augmented successfully.\n",
            "Video 'shop_lifter_77.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_201.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_2.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_15.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_93.mp4' augmented successfully.\n",
            "Video 'shop_lifter_109.mp4' augmented successfully.\n",
            "Video 'shop_lifter_46.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_65.mp4' augmented successfully.\n",
            "Video 'shop_lifter_103.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_75.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_148.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_167_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_49.mp4' augmented successfully.\n",
            "Video 'shop_lifter_72.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_151_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_79.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_5_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_29.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_93_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_57.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_63.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_22_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_86.mp4' augmented successfully.\n",
            "Video 'shop_lifter_44.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_69.mp4' augmented successfully.\n",
            "Video 'shop_lifter_35.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_148_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_187_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_100.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_205.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_9.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_32.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_149_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_25_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_17.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_136.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_176.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_188_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_217.mp4' augmented successfully.\n",
            "Video 'shop_lifter_120.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_6.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_95_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_125_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_38_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_34_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_111_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_0.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_118_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_139_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_50.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_51.mp4' augmented successfully.\n",
            "Video 'shop_lifter_39.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_176_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_209.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_209_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_8_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_90.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_140_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_145.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_91_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_170.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_180_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_30_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_211_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_132_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_122_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_172_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_41.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_203_1.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_210.mp4' augmented successfully.\n",
            "Video 'shop_lifter_n_207_1.mp4' augmented successfully.\n",
            "Video augmentation completed.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define input directory\n",
        "input_dir = '/tmp/first_128_files'\n",
        "\n",
        "# Define output directory\n",
        "output_dir = '/tmp/augmented_shopliftingg'\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Function to check if a file is an MP4 video\n",
        "def is_mp4(filename):\n",
        "    return filename.endswith('.mp4')\n",
        "\n",
        "# List MP4 videos in the input directory\n",
        "videos = [filename for filename in os.listdir(input_dir) if is_mp4(filename)]\n",
        "\n",
        "# Augment videos\n",
        "for video in videos:\n",
        "    input_path = os.path.join(input_dir, video)\n",
        "    output_path = os.path.join(output_dir, video)\n",
        "\n",
        "    # Open video file\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    # Check if video is accessible and valid\n",
        "    if cap.isOpened():\n",
        "        # Read first frame\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # Check if frame is valid\n",
        "        if ret:\n",
        "            # Create output video writer\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "            # Process and write frames\n",
        "            while ret:\n",
        "                # Augment frame here (e.g., flip horizontally)\n",
        "                augmented_frame = cv2.flip(frame, 1)\n",
        "\n",
        "                # Write augmented frame to output video\n",
        "                out.write(augmented_frame)\n",
        "\n",
        "                # Read next frame\n",
        "                ret, frame = cap.read()\n",
        "\n",
        "            # Release video capture and writer\n",
        "            cap.release()\n",
        "            out.release()\n",
        "\n",
        "            print(f\"Video '{video}' augmented successfully.\")\n",
        "        else:\n",
        "            print(f\"Error: Unable to read frame from video '{video}'.\")\n",
        "    else:\n",
        "        print(f\"Error: Unable to open video '{video}'.\")\n",
        "\n",
        "print(\"Video augmentation completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8ESU43HqVdA"
      },
      "source": [
        "Append the original video to the file containing augmented data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNLCmou6DMi2",
        "outputId": "fcac073c-7c36-4e3f-9d37-5418acbc2742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original video 'shop_lifter_3.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_3.mp4'.\n",
            "Video 'shop_lifter_3.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_57.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_57.mp4'.\n",
            "Video 'shop_lifter_57.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_71.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_71.mp4'.\n",
            "Video 'shop_lifter_n_71.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_94_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_94_1.mp4'.\n",
            "Video 'shop_lifter_n_94_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_42.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_42.mp4'.\n",
            "Video 'shop_lifter_n_42.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_129_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_129_1.mp4'.\n",
            "Video 'shop_lifter_n_129_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_154.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_154.mp4'.\n",
            "Video 'shop_lifter_n_154.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_40_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_40_1.mp4'.\n",
            "Video 'shop_lifter_n_40_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_114.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_114.mp4'.\n",
            "Video 'shop_lifter_114.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_41.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_41.mp4'.\n",
            "Video 'shop_lifter_41.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_158_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_158_1.mp4'.\n",
            "Video 'shop_lifter_n_158_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_29.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_29.mp4'.\n",
            "Video 'shop_lifter_29.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_51.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_51.mp4'.\n",
            "Video 'shop_lifter_51.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_48.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_48.mp4'.\n",
            "Video 'shop_lifter_n_48.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_23.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_23.mp4'.\n",
            "Video 'shop_lifter_23.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_121.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_121.mp4'.\n",
            "Video 'shop_lifter_n_121.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_103.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_103.mp4'.\n",
            "Video 'shop_lifter_n_103.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_66.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_66.mp4'.\n",
            "Video 'shop_lifter_66.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_105_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_105_1.mp4'.\n",
            "Video 'shop_lifter_n_105_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_215_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_215_1.mp4'.\n",
            "Video 'shop_lifter_n_215_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_112.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_112.mp4'.\n",
            "Video 'shop_lifter_n_112.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_34.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_34.mp4'.\n",
            "Video 'shop_lifter_n_34.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_124.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_124.mp4'.\n",
            "Video 'shop_lifter_n_124.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_28.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_28.mp4'.\n",
            "Video 'shop_lifter_n_28.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_3.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_3.mp4'.\n",
            "Video 'shop_lifter_n_3.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_42.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_42.mp4'.\n",
            "Video 'shop_lifter_42.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_51_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_51_1.mp4'.\n",
            "Video 'shop_lifter_n_51_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_27.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_27.mp4'.\n",
            "Video 'shop_lifter_n_27.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_179_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_179_1.mp4'.\n",
            "Video 'shop_lifter_n_179_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_26.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_26.mp4'.\n",
            "Video 'shop_lifter_n_26.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_192_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_192_1.mp4'.\n",
            "Video 'shop_lifter_n_192_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_173_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_173_1.mp4'.\n",
            "Video 'shop_lifter_n_173_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_106_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_106_1.mp4'.\n",
            "Video 'shop_lifter_n_106_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_72_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_72_1.mp4'.\n",
            "Video 'shop_lifter_n_72_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_108_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_108_1.mp4'.\n",
            "Video 'shop_lifter_n_108_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_110.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_110.mp4'.\n",
            "Video 'shop_lifter_110.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_136_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_136_1.mp4'.\n",
            "Video 'shop_lifter_n_136_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_194_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_194_1.mp4'.\n",
            "Video 'shop_lifter_n_194_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_121_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_121_1.mp4'.\n",
            "Video 'shop_lifter_n_121_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_191_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_191_1.mp4'.\n",
            "Video 'shop_lifter_n_191_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_65.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_65.mp4'.\n",
            "Video 'shop_lifter_65.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_142_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_142_1.mp4'.\n",
            "Video 'shop_lifter_n_142_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_38.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_38.mp4'.\n",
            "Video 'shop_lifter_38.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_18.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_18.mp4'.\n",
            "Video 'shop_lifter_18.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_110.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_110.mp4'.\n",
            "Video 'shop_lifter_n_110.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_16.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_16.mp4'.\n",
            "Video 'shop_lifter_16.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_183_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_183_1.mp4'.\n",
            "Video 'shop_lifter_n_183_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_100.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_100.mp4'.\n",
            "Video 'shop_lifter_n_100.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_71_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_71_1.mp4'.\n",
            "Video 'shop_lifter_n_71_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_190.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_190.mp4'.\n",
            "Video 'shop_lifter_n_190.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_17.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_17.mp4'.\n",
            "Video 'shop_lifter_n_17.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_89.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_89.mp4'.\n",
            "Video 'shop_lifter_n_89.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_178.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_178.mp4'.\n",
            "Video 'shop_lifter_n_178.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_10.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_10.mp4'.\n",
            "Video 'shop_lifter_10.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_25.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_25.mp4'.\n",
            "Video 'shop_lifter_25.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_15_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_15_1.mp4'.\n",
            "Video 'shop_lifter_n_15_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_125.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_125.mp4'.\n",
            "Video 'shop_lifter_125.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_77.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_77.mp4'.\n",
            "Video 'shop_lifter_77.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_201.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_201.mp4'.\n",
            "Video 'shop_lifter_n_201.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_2.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_2.mp4'.\n",
            "Video 'shop_lifter_n_2.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_15.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_15.mp4'.\n",
            "Video 'shop_lifter_n_15.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_93.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_93.mp4'.\n",
            "Video 'shop_lifter_n_93.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_109.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_109.mp4'.\n",
            "Video 'shop_lifter_109.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_46.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_46.mp4'.\n",
            "Video 'shop_lifter_46.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_65.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_65.mp4'.\n",
            "Video 'shop_lifter_n_65.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_103.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_103.mp4'.\n",
            "Video 'shop_lifter_103.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_75.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_75.mp4'.\n",
            "Video 'shop_lifter_n_75.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_148.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_148.mp4'.\n",
            "Video 'shop_lifter_n_148.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_167_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_167_1.mp4'.\n",
            "Video 'shop_lifter_n_167_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_49.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_49.mp4'.\n",
            "Video 'shop_lifter_n_49.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_72.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_72.mp4'.\n",
            "Video 'shop_lifter_72.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_151_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_151_1.mp4'.\n",
            "Video 'shop_lifter_n_151_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_79.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_79.mp4'.\n",
            "Video 'shop_lifter_n_79.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_5_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_5_1.mp4'.\n",
            "Video 'shop_lifter_n_5_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_29.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_29.mp4'.\n",
            "Video 'shop_lifter_n_29.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_93_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_93_1.mp4'.\n",
            "Video 'shop_lifter_n_93_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_57.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_57.mp4'.\n",
            "Video 'shop_lifter_n_57.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_63.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_63.mp4'.\n",
            "Video 'shop_lifter_n_63.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_22_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_22_1.mp4'.\n",
            "Video 'shop_lifter_n_22_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_86.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_86.mp4'.\n",
            "Video 'shop_lifter_n_86.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_44.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_44.mp4'.\n",
            "Video 'shop_lifter_44.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_69.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_69.mp4'.\n",
            "Video 'shop_lifter_n_69.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_35.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_35.mp4'.\n",
            "Video 'shop_lifter_35.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_148_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_148_1.mp4'.\n",
            "Video 'shop_lifter_n_148_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_187_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_187_1.mp4'.\n",
            "Video 'shop_lifter_n_187_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_100.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_100.mp4'.\n",
            "Video 'shop_lifter_100.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_205.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_205.mp4'.\n",
            "Video 'shop_lifter_n_205.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_9.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_9.mp4'.\n",
            "Video 'shop_lifter_n_9.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_32.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_32.mp4'.\n",
            "Video 'shop_lifter_n_32.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_149_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_149_1.mp4'.\n",
            "Video 'shop_lifter_n_149_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_25_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_25_1.mp4'.\n",
            "Video 'shop_lifter_n_25_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_17.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_17.mp4'.\n",
            "Video 'shop_lifter_17.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_136.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_136.mp4'.\n",
            "Video 'shop_lifter_n_136.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_176.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_176.mp4'.\n",
            "Video 'shop_lifter_n_176.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_188_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_188_1.mp4'.\n",
            "Video 'shop_lifter_n_188_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_217.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_217.mp4'.\n",
            "Video 'shop_lifter_n_217.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_120.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_120.mp4'.\n",
            "Video 'shop_lifter_120.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_6.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_6.mp4'.\n",
            "Video 'shop_lifter_n_6.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_95_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_95_1.mp4'.\n",
            "Video 'shop_lifter_n_95_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_125_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_125_1.mp4'.\n",
            "Video 'shop_lifter_n_125_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_38_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_38_1.mp4'.\n",
            "Video 'shop_lifter_n_38_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_34_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_34_1.mp4'.\n",
            "Video 'shop_lifter_n_34_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_111_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_111_1.mp4'.\n",
            "Video 'shop_lifter_n_111_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_0.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_0.mp4'.\n",
            "Video 'shop_lifter_0.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_118_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_118_1.mp4'.\n",
            "Video 'shop_lifter_n_118_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_139_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_139_1.mp4'.\n",
            "Video 'shop_lifter_n_139_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_50.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_50.mp4'.\n",
            "Video 'shop_lifter_50.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_51.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_51.mp4'.\n",
            "Video 'shop_lifter_n_51.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_39.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_39.mp4'.\n",
            "Video 'shop_lifter_39.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_176_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_176_1.mp4'.\n",
            "Video 'shop_lifter_n_176_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_209.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_209.mp4'.\n",
            "Video 'shop_lifter_n_209.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_209_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_209_1.mp4'.\n",
            "Video 'shop_lifter_n_209_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_8_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_8_1.mp4'.\n",
            "Video 'shop_lifter_n_8_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_90.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_90.mp4'.\n",
            "Video 'shop_lifter_n_90.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_140_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_140_1.mp4'.\n",
            "Video 'shop_lifter_n_140_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_145.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_145.mp4'.\n",
            "Video 'shop_lifter_n_145.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_91_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_91_1.mp4'.\n",
            "Video 'shop_lifter_n_91_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_170.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_170.mp4'.\n",
            "Video 'shop_lifter_n_170.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_180_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_180_1.mp4'.\n",
            "Video 'shop_lifter_n_180_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_30_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_30_1.mp4'.\n",
            "Video 'shop_lifter_n_30_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_211_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_211_1.mp4'.\n",
            "Video 'shop_lifter_n_211_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_132_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_132_1.mp4'.\n",
            "Video 'shop_lifter_n_132_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_122_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_122_1.mp4'.\n",
            "Video 'shop_lifter_n_122_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_172_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_172_1.mp4'.\n",
            "Video 'shop_lifter_n_172_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_41.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_41.mp4'.\n",
            "Video 'shop_lifter_n_41.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_203_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_203_1.mp4'.\n",
            "Video 'shop_lifter_n_203_1.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_210.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_210.mp4'.\n",
            "Video 'shop_lifter_n_210.mp4' augmented successfully.\n",
            "Original video 'shop_lifter_n_207_1.mp4' copied to '/tmp/augmented_shopliftingg/original_shop_lifter_n_207_1.mp4'.\n",
            "Video 'shop_lifter_n_207_1.mp4' augmented successfully.\n",
            "Video augmentation completed.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define input directory\n",
        "input_dir = '/tmp/first_128_files'\n",
        "\n",
        "# Define output directory\n",
        "output_dir = '/tmp/augmented_shopliftingg'\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Function to check if a file is an MP4 video\n",
        "def is_mp4(filename):\n",
        "    return filename.endswith('.mp4')\n",
        "\n",
        "# List MP4 videos in the input directory\n",
        "videos = [filename for filename in os.listdir(input_dir) if is_mp4(filename)]\n",
        "\n",
        "# Augment videos\n",
        "for video in videos:\n",
        "    input_path = os.path.join(input_dir, video)\n",
        "\n",
        "    # Copy original video file to output directory with a new name\n",
        "    new_video_name = f\"original_{video}\"\n",
        "    output_original_path = os.path.join(output_dir, new_video_name)\n",
        "    shutil.copy(input_path, output_original_path)\n",
        "    print(f\"Original video '{video}' copied to '{output_original_path}'.\")\n",
        "\n",
        "    # Open video file\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    # Check if video is accessible and valid\n",
        "    if cap.isOpened():\n",
        "        # Read first frame\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # Check if frame is valid\n",
        "        if ret:\n",
        "            # Create output video writer\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            output_path = os.path.join(output_dir, video)\n",
        "            out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "            # Process and write frames\n",
        "            while ret:\n",
        "                # Augment frame here (e.g., flip horizontally)\n",
        "                augmented_frame = cv2.flip(frame, 1)\n",
        "\n",
        "                # Write augmented frame to output video\n",
        "                out.write(augmented_frame)\n",
        "\n",
        "                # Read next frame\n",
        "                ret, frame = cap.read()\n",
        "\n",
        "            # Release video capture and writer\n",
        "            cap.release()\n",
        "            out.release()\n",
        "\n",
        "            print(f\"Video '{video}' augmented successfully.\")\n",
        "        else:\n",
        "            print(f\"Error: Unable to read frame from video '{video}'.\")\n",
        "    else:\n",
        "        print(f\"Error: Unable to open video '{video}'.\")\n",
        "\n",
        "print(\"Video augmentation completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4KSRVTWuJuO"
      },
      "source": [
        "Removing the first 128 file to make the all data is not Shop Lifting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZm7cQl9nqJA",
        "outputId": "580faf30-4737-4f70-c4e6-c073240ef5dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files after removing the first 128 file: 365\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define paths\n",
        "source_folder = '/content/drive/MyDrive/Phase 1 Dataset/not Shop Lifters'\n",
        "destination_folder = '/tmp/not_Shop_Lifters_Copyyy'\n",
        "\n",
        "# Create a copy of the \"not Shop Lifters\" folder in the \"/tmp\" directory\n",
        "shutil.copytree(source_folder, destination_folder)\n",
        "\n",
        "# Remove the first 128 files from the copied folder\n",
        "files_to_remove = os.listdir(destination_folder)[:200]\n",
        "for file_name in files_to_remove:\n",
        "    file_path = os.path.join(destination_folder, file_name)\n",
        "    os.remove(file_path)\n",
        "\n",
        "# Augment the rest of the data in the copied folder (assuming you have an augmentation function)\n",
        "# Here you can implement your data augmentation code\n",
        "\n",
        "# After augmentation, you can print the number of files in the copied folder to verify\n",
        "print(\"Number of files after removing the first 128 file:\", len(os.listdir(destination_folder)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VQdJoJ5uoRc"
      },
      "source": [
        "Count all data in Shop Lifting Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70UrWFCST8nc",
        "outputId": "93237758-ce53-42fb-c9d1-161a06355198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of items in the folder: 256\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the directory to check\n",
        "folder_path = '/tmp/augmented_shopliftingg'\n",
        "\n",
        "# List all files and directories in the folder\n",
        "items_in_folder = os.listdir(folder_path)\n",
        "\n",
        "# Count the number of items\n",
        "num_items = len(items_in_folder)\n",
        "\n",
        "print(\"Number of items in the folder:\", num_items)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "javYEyD2vIuS"
      },
      "source": [
        "Randomly select one video from each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu_UrUHJyAXh",
        "outputId": "e93f6296-5f23-4a85-f520-fdc31439d005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected class name from /tmp/augmented_shopliftingg: shop_lifter_n_172_1.mp4\n",
            "Selected class name from /tmp/not_Shop_Lifters_Copyyy: shop_lifter_n_77.mp4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Specify the directory paths\n",
        "augmented_shoplifting_dir = '/tmp/augmented_shopliftingg'\n",
        "not_shop_lifters_dir = '/tmp/not_Shop_Lifters_Copyyy'\n",
        "\n",
        "# Check if the directories exist\n",
        "if os.path.exists(augmented_shoplifting_dir) and os.path.exists(not_shop_lifters_dir):\n",
        "    # Iterate over each directory\n",
        "    for directory in [augmented_shoplifting_dir, not_shop_lifters_dir]:\n",
        "        # Get the list of class names\n",
        "        all_classes_names = os.listdir(directory)\n",
        "\n",
        "        # Check if the list is not empty\n",
        "        if all_classes_names:\n",
        "            # Generate random index\n",
        "            random_index = random.randint(0, len(all_classes_names) - 1)\n",
        "            # Retrieve a random class name\n",
        "            selected_class_name = all_classes_names[random_index]\n",
        "            # Print the selected class name\n",
        "            print(f\"Selected class name from {directory}: {selected_class_name}\")\n",
        "        else:\n",
        "            print(f\"No classes found in {directory}\")\n",
        "else:\n",
        "    print(\"Directory not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qNNQ6yyKxl_g"
      },
      "outputs": [],
      "source": [
        "# Specify the height and width to which each video frame will be resized in our dataset.\n",
        "IMAGE_HEIGHT , IMAGE_WIDTH = 80,80\n",
        "\n",
        "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
        "SEQUENCE_LENGTH = 20\n",
        "\n",
        "# Specify the directory containing the shoplifting dataset.\n",
        "DATASET_DIR = \"/tmp\"\n",
        "\n",
        "\n",
        "# Specify the list containing the names of the classes used for training.\n",
        "CLASSES_LIST = [\"not_Shop_Lifters_Copyyy\",\"augmented_shopliftingg\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "X3DlH7WulHOC"
      },
      "outputs": [],
      "source": [
        "def frames_extraction(video_path):\n",
        "    '''\n",
        "    This function will extract the required frames from a video after resizing and normalizing them.\n",
        "    Args:\n",
        "        video_path: The path of the video in the disk, whose frames are to be extracted.\n",
        "    Returns:\n",
        "        frames_list: A list containing the resized and normalized frames of the video.\n",
        "    '''\n",
        "\n",
        "    # Declare a list to store video frames.\n",
        "    frames_list = []\n",
        "\n",
        "    # Read the Video File using the VideoCapture object.\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get the total number of frames in the video.\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate the the interval after which frames will be added to the list.\n",
        "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
        "\n",
        "    # Iterate through the Video Frames.\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "        # Set the current frame position of the video.\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "        # Reading the frame from the video.\n",
        "        success, frame = video_reader.read()\n",
        "\n",
        "        # Check if Video frame is not successfully read then break the loop\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed height and width.\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "\n",
        "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        # Append the normalized frame into the frames list\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "    # Release the VideoCapture object.\n",
        "    video_reader.release()\n",
        "\n",
        "    # Return the frames list.\n",
        "    return frames_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "GAgKgN3Cp3wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4927742-d6ef-4179-818a-e188ca8c4472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal 365\n",
            "shoplifting 256\n"
          ]
        }
      ],
      "source": [
        "print('normal', len(os.listdir('/tmp/not_Shop_Lifters_Copyyy')))\n",
        "print('shoplifting', len(os.listdir('/tmp/augmented_shopliftingg')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "lJ8xWux8rdUy"
      },
      "outputs": [],
      "source": [
        "def create_dataset():\n",
        "    '''\n",
        "    This function will extract the data of the selected classes and create the\n",
        "    required dataset.\n",
        "    Returns:\n",
        "        features:          A list containing the extracted frames of the videos.\n",
        "        labels:            A list containing the indexes of the classes associated with the videos.\n",
        "        video_files_paths: A list containing the paths of the videos in the disk.\n",
        "    '''\n",
        "\n",
        "    # Declared Empty Lists to store the features, labels and video file path values.\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "\n",
        "        # Display the name of the class whose data is being extracted.\n",
        "        print(f'Extracting Data of Class: {class_name}')\n",
        "\n",
        "        # Get the list of video files present in the specific class name directory.\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "\n",
        "        # Iterate through all the files present in the files list.\n",
        "        for file_name in files_list:\n",
        "\n",
        "            # Get the complete video path.\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "\n",
        "            # Extract the frames of the video file.\n",
        "            frames = frames_extraction(video_file_path)\n",
        "\n",
        "            # Check if the extracted frames are equal to the SEQUENCE_LENGTH specified above.\n",
        "            # So ignore the videOs having frames less than the SEQUENCE_LENGTH.\n",
        "            if len(frames) == SEQUENCE_LENGTH:\n",
        "\n",
        "                # Append the data to their repective lists.\n",
        "                features.append(frames)\n",
        "                labels.append(class_index)\n",
        "                video_files_paths.append(video_file_path)\n",
        "\n",
        "    # Converting the list to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Return the frames, class index, and video file path.\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5NdTUcftycHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14d7fcf-6c0e-44b2-cca4-b961c62c4a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 1121951555157241182\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "0sNN5aUxyfxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f97cc1b-d197-4f16-99b3-f03e6948ecb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: not_Shop_Lifters_Copyyy\n",
            "Extracting Data of Class: augmented_shopliftingg\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset.\n",
        "features, labels, video_files_paths = create_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "nX6-90VWTKJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d34749-7fc7-4db2-82cb-63aea69a0a0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(621, 20, 80, 80, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "LhbmKDbcWJax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd77028-8a70-4e7b-ca64-da49775a6b2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(621,)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "9-Rj0EIQWLLq"
      },
      "outputs": [],
      "source": [
        "# Using Keras's to_categorical method to convert labels into one-hot-encoded vectors\n",
        "one_hot_encoded_labels = to_categorical(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "eGGxGRP_WMtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ca7df5-d002-4397-fbc4-7847510578bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(621, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "one_hot_encoded_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "NlDhBg8mWN-5"
      },
      "outputs": [],
      "source": [
        "# Split the Data into Train ( 75% ) and Test Set ( 25% ).\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels,\n",
        "                                                                            test_size = 0.25, shuffle = True,\n",
        "                                                                            random_state = seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mchnK7AFLloE"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation\n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "\n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "\n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "XSJceJDD8ttU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf89f461-07fc-4c10-b3a3-fd314c258fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_3 (Conv3D)           (None, 18, 78, 78, 32)    2624      \n",
            "                                                                 \n",
            " max_pooling3d_3 (MaxPoolin  (None, 9, 39, 39, 32)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 7, 37, 37, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_4 (MaxPoolin  (None, 3, 18, 18, 64)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " conv3d_5 (Conv3D)           (None, 1, 16, 16, 128)    221312    \n",
            "                                                                 \n",
            " max_pooling3d_5 (MaxPoolin  (None, 1, 8, 8, 128)      0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2377218 (9.07 MB)\n",
            "Trainable params: 2377218 (9.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_action_recognition_model(input_shape, num_classes):\n",
        "    # Define the 3D CNN model\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # 1st layer group: Conv3D + MaxPooling3D\n",
        "    model.add(layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "    # 2nd layer group: Conv3D + MaxPooling3D\n",
        "    model.add(layers.Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "    # 3rd layer group: Conv3D + MaxPooling3D\n",
        "    model.add(layers.Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "\n",
        "    # Flatten the output for fully connected layers\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Set input shape (depth, height, width, channels) and number of classes\n",
        "input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)  # Assuming RGB frames\n",
        "num_classes = len(CLASSES_LIST)\n",
        "\n",
        "# Build the action recognition model\n",
        "action_recognition_model = build_action_recognition_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "action_recognition_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "action_recognition_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "_bQJ7o0TA-33"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "action_recognition_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Swb4PtKvBLzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d991d1e-f4ce-4442-e409-f8d34818d166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "17/17 [==============================] - 239s 14s/step - loss: 0.7139 - accuracy: 0.6710\n",
            "Epoch 2/10\n",
            "17/17 [==============================] - 246s 14s/step - loss: 0.4785 - accuracy: 0.7892\n",
            "Epoch 3/10\n",
            "17/17 [==============================] - 239s 14s/step - loss: 0.4714 - accuracy: 0.7892\n",
            "Epoch 4/10\n",
            "17/17 [==============================] - 239s 14s/step - loss: 0.4738 - accuracy: 0.7892\n",
            "Epoch 5/10\n",
            "17/17 [==============================] - 235s 14s/step - loss: 0.4743 - accuracy: 0.7892\n",
            "Epoch 6/10\n",
            "17/17 [==============================] - 242s 14s/step - loss: 0.4715 - accuracy: 0.7892\n",
            "Epoch 7/10\n",
            "17/17 [==============================] - 244s 14s/step - loss: 0.4668 - accuracy: 0.7892\n",
            "Epoch 8/10\n",
            "17/17 [==============================] - 239s 14s/step - loss: 0.4772 - accuracy: 0.7892\n",
            "Epoch 9/10\n",
            "17/17 [==============================] - 237s 14s/step - loss: 0.4703 - accuracy: 0.7892\n",
            "Epoch 10/10\n",
            "17/17 [==============================] - 239s 14s/step - loss: 0.4714 - accuracy: 0.7892\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = action_recognition_model.fit(\n",
        "    x=features_train,\n",
        "    y=labels_train,\n",
        "    batch_size=28,\n",
        "    epochs=10,\n",
        "    verbose=1  # Set to 1 for progress bar, 0 for silent\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7NaDw0YNHm8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "jAWGN9WHCsPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0698030-96a3-48c5-f5e2-21b39ecab2a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 24s 5s/step - loss: 0.4336 - accuracy: 0.8077\n",
            "Test Loss: 0.4335978031158447\n",
            "Test Accuracy: 0.807692289352417\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test data\n",
        "loss, accuracy = action_recognition_model.evaluate(features_test, labels_test, verbose=1)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,roc_curve,ConfusionMatrixDisplay\n",
        "\n",
        "k = action_recognition_model.predict(features_test,batch_size=3)\n",
        "y_pred = np.argmax(k,axis=1)\n",
        "y_true = np.argmax(labels_test,axis=1)\n",
        "\n",
        "ConfusionMatrixDisplay(confusion_matrix(y_true,y_pred)).plot()"
      ],
      "metadata": {
        "id": "VtAtQYHBe2pk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "e5d6f0a8-242e-4ff5-cb93-0bf2e81a25c6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 34s 652ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7d3009887070>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in HDF5 format\n",
        "action_recognition_model.save('/path/to/save/modelll.h5', save_format='h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlIaKJefIWfG",
        "outputId": "acc6b9f9-daa3-4efd-e687-7b1768483775"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Path to your saved model file\n",
        "model_path = '/path/to/save/modelll.h5'\n",
        "\n",
        "# Upload the model file to Google Drive\n",
        "file_name = 'modelll.h5'  # Name for the uploaded file\n",
        "file = drive.CreateFile({'title': file_name})\n",
        "file.SetContentFile(model_path)\n",
        "file.Upload()\n",
        "\n",
        "# Get the link to the uploaded file\n",
        "print('Uploaded file with ID {}'.format(file.get('id')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wjXUd-iIewc",
        "outputId": "a88637dd-a1a9-4827-b344-563a58503060"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file with ID 16ltqx1BQ_s_ASDDDYa8JzwuWCEupiwWc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_recognition_model.save()"
      ],
      "metadata": {
        "id": "EP983AFdIF8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_action(video_file_path, SEQUENCE_LENGTH):\n",
        "    '''\n",
        "    This function will perform single action recognition prediction on a video using the LRCN model.\n",
        "    Args:\n",
        "    video_file_path:  The path of the video stored in the disk on which the action recognition is to be performed.\n",
        "    SEQUENCE_LENGTH:  The fixed number of frames of a video that can be passed to the model as one sequence.\n",
        "    '''\n",
        "\n",
        "    # Initialize the VideoCapture object to read from the video file.\n",
        "    video_reader = cv2.VideoCapture(video_file_path)\n",
        "\n",
        "    # Get the width and height of the video.\n",
        "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Declare a list to store video frames we will extract.\n",
        "    frames_list = []\n",
        "\n",
        "    # Initialize a variable to store the predicted action being performed in the video.\n",
        "    predicted_class_name = ''\n",
        "\n",
        "    # Get the number of frames in the video.\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate the interval after which frames will be added to the list.\n",
        "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
        "\n",
        "    # Iterating the number of times equal to the fixed length of sequence.\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "        # Set the current frame position of the video.\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "        # Read a frame.\n",
        "        success, frame = video_reader.read()\n",
        "\n",
        "        # Check if frame is not read properly then break the loop.\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed Dimensions.\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "\n",
        "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1.\n",
        "        normalized_frame = resized_frame / 255\n",
        "\n",
        "        # Appending the pre-processed frame into the frames list\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "    # Passing the  pre-processed frames to the model and get the predicted probabilities.\n",
        "    predicted_labels_probabilities = action_recognition_model.predict(np.expand_dims(frames_list, axis = 0))[0]\n",
        "\n",
        "    # Get the index of class with highest probability.\n",
        "    predicted_label = np.argmax(predicted_labels_probabilities)\n",
        "\n",
        "    # Get the class name using the retrieved index.\n",
        "    predicted_class_name = CLASSES_LIST[predicted_label]\n",
        "\n",
        "    # Display the predicted action along with the prediction confidence.\n",
        "    print(f'Action Predicted: {predicted_class_name}\\nConfidence: {predicted_labels_probabilities[predicted_label]}')\n",
        "\n",
        "    # Release the VideoCapture object.\n",
        "    video_reader.release()"
      ],
      "metadata": {
        "id": "IkIBlVEzfTGM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def show_video(video_path, video_width = 600):\n",
        "\n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")"
      ],
      "metadata": {
        "id": "drkn1MyUf55f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_dK_CKgL5BR"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Video\n",
        "input_video_file_path = \"/content/drive/MyDrive/WhatsApp Video 2024-03-01 at 9.59.53 PM (3).mp4\"\n",
        "predict_single_action(input_video_file_path, SEQUENCE_LENGTH)\n",
        "\n",
        "# Display the input video.\n",
        "show_video(input_video_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6Po3JdZOjZc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
